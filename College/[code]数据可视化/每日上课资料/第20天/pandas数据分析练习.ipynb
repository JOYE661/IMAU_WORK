{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 背景介绍\n",
    "\n",
    "本数据集包括了2015年至2017年我国36个主要一线城市、特区的一些年度数据，包括产值、人口、就业、教育、医疗、经济贸易、房地产投资等方面。\n",
    "\n",
    "#### 包含文件：\n",
    "- 2015年国内主要城市年度数据.csv\n",
    "- 2016年国内主要城市年度数据.csv\n",
    "- 2017年国内主要城市年度数据.csv \n",
    "\n",
    "### 数据特征\n",
    "\n",
    "|数据集名称 \t|数据类型 \t|特征数 \t|包含城市数量 \t|缺失值 \t|相关人物|\n",
    "|:----|:----|:----|:----|:----|:----|\n",
    "|国内主要城市年度数据| 数值型、字符型| \t13|\t36| 有| \t描述性分析（可视化）等|\n",
    "\n",
    "### 数据属性\n",
    "\n",
    "|NO \t|字段名称 \t|数据类型 \t|字段描述|\n",
    "|:----|:----|:----|:----|\n",
    "|1 \t|地区 \t|String \t|城市名称|\n",
    "|2 \t|年份 \t|Int \t|数据所对应的时间|\n",
    "|3 \t|国内生产总值 \t|Float \t|单位：亿元|\n",
    "|4 \t|第一产业增加值 \t|Float \t|单位：亿元|\n",
    "|5 \t|第二产业增加值 \t|Float \t|单位：亿元|\n",
    "|6 \t|第三产业增加值 \t|Float \t|单位：亿元|\n",
    "|7 \t|社会商品零售总额 \t|Float \t|单位：亿元|\n",
    "|8 \t|货物进出口总额 \t|Float \t|单位：百万美元|\n",
    "|9 \t|年末总人口 \t|Float \t|单位：万人\n",
    "|10 \t|在岗职工平均工资 \t|Int \t|单位：元|\n",
    "|11 \t|普通高等学校在校学生数 \t|Float \t|单位：万人|\n",
    "|12 \t|医院、卫生院数 \t|Int \t|单位：个|\n",
    "|13 \t|房地产开发投资额 \t|Float \t|单位：亿元|\n",
    "\n",
    "数据来源\n",
    "\n",
    "国家统计局:https://data.stats.gov.cn/easyquery.htm?cn=E0105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析非常常用的知识点，知识点概述如下：\n",
    "\n",
    "    1、数据集基本信息探索\n",
    "        数据基本情况\n",
    "        数量探索\n",
    "        相关性分析\n",
    "        绘总统计\n",
    "        数据抽样\n",
    "    2、应用函数 apply\n",
    "    3、合并数据\n",
    "    4、索引问题\n",
    "    5、排序问题\n",
    "    6、重复数据处理\n",
    "    7、数据分组\n",
    "    8、处理缺失值\n",
    "    9、选择数据\n",
    "    10、pandas时间序列\n",
    "    11、pandas可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、pandas 基本信息探索\n",
    "#### (1) 基本情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 中文设置\n",
    "plt.rcParams['font.sans-serif'] = [\"SimHei\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2015年国内主要城市年度数据.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--' * 20, '\\n【1】数据集基本情况探索')\n",
    "\n",
    "print('\\n>>>样本形状:\\n', df.shape) # 样本形状、样本数、特征数探索\n",
    "print('\\n>>>样本索引、列名探索:\\n', df.index, df.columns)  # 样本索引、索引转换成列表、列名探索\n",
    "print('\\n>>>某列类型、全部样本类型探索:\\n', df['年份'].dtypes, '\\n', df.dtypes)  # 某列类型、全部样本类型探索\n",
    "print('\\n>>>')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 数量探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索某列、全部样本非 NA 值的数量\n",
    "print(df['年份'].count(), '\\n', df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索某列的值，也可以探索全部样本的值\n",
    "df['年份'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# value_counts探索某列中各元素值出现的次数(只能探索某列的) \n",
    "# count 计算每列或每行的非NA单元格。\n",
    "df['第一产业增加值'].value_counts().head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique()函数用于获取Series对象的唯一值。唯一性按出现顺序返回。基于哈希表的唯一，因此不排序\n",
    "print(\"唯一值:\\n\",df['国内生产总值'].unique()) \n",
    "# nunique唯一值得数量\n",
    "print(\"\\n唯一值的数量:\\n\",df['国内生产总值'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 探索每一列缺失值数量\n",
    "print(\"探索每一列缺失值数量:\\n\",df.isnull().sum()) \n",
    "# 不是缺失值数量\n",
    "print(\"\\n不是缺失值数量:\\n\",df.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 某列取值、多列取值\n",
    "print('取出一列:\\n', df['年份'].head(),\"类型:\",type(df['年份']))\n",
    "\n",
    "#取出多列:\n",
    "print('\\n取出多列:\\n', df[['地区', '年份']].head(), \"类型:\", type(df[['地区', '年份']]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 相关性分析\n",
    "探索特征之间相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索某列、全部样本的方差\n",
    "print('年末总人口方差:\\n', df['年末总人口'].var())\n",
    "\n",
    "print('\\n总体数据方差:\\n', df.var(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 探索某列、全部样本的标准差\n",
    "print('年末总人口标准差:\\n', df['年末总人口'].std())\n",
    "\n",
    "print('\\n总体数据标准差:\\n', df.std(), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (4) 汇总统计\n",
    "样本数据汇总统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一列求和\n",
    "print('每一列求和:\\n', df.sum())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 某列逐行累加(可以全部样本每一列都累加)\n",
    "print(df['地区'].cumsum().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最大最小值\n",
    "print('最大值>>>\\n', df.max().head())  \n",
    "print('\\n最小值>>>\\n', df.min().head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回 '国内生产总值' 列最大、最小值所对应的索引号\n",
    "print('\\n>>>', df['国内生产总值'].idxmax(), '\\n', df['国内生产总值'].idxmin()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n>>>', df.mean(), df.median())  # 平均值、中位数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 汇总统计信息，是上面方法的统一\n",
    "print('\\n>>>', df.describe().T)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (columnName, columnData) in df.describe().iteritems(): \n",
    "    print('Colunm Name : ', columnName) \n",
    "    print('Column Contents : ', columnData.values) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (5) 数据抽样\n",
    "有时候我们做研究分析或者数据量过大时，\n",
    "只希望抽取一部分数据做研究，因此要进行数据抽样处理 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace允许或不允许对同一行进行多次采样\n",
    "data = df.sample(n=5, replace=False)  # 不放回随机抽样 5 个数据\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、pandas 中的应用函数 apply\n",
    "我们发现数据集中有浮点型数据，但是我们只需要整形数据，\n",
    "因此我们很有必要使用应用函数对原数据进行类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fun(x):\n",
    "    x = int(x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "\n",
    "data1 = df['国内生产总值'].apply(fun)\n",
    "\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x + 'QQ'\n",
    "\n",
    "data2 = df['地区'].apply(f)\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = df.iloc[:, :].apply(np.sum)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、合并数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/2015年国内主要城市年度数据.csv') \n",
    "df2 = pd.read_csv('data/2016年国内主要城市年度数据.csv') \n",
    "df3 = pd.read_csv('data/2017年国内主要城市年度数据.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通常用来连接DataFrame对象。默认情况下是对两个DataFrame对象进行纵向连接， \n",
    "# 当然通过设置参数，也可以通过它实现DataFrame对象的横向连接\n",
    "df_1 = pd.concat(objs=[df1, df2, df3], axis=0)  # 合并数据，以行的维度合并\n",
    "df_1.sample(n=7, replace=False)  # 随机不放回抽样 7 个数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 以指定值合并，在本案例中不实用\n",
    "df_2 = pd.merge(left=df1, right=df2, on='年份', how='outer') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、索引问题\n",
    "单个索引，inplace=False 不覆盖的情况下，\n",
    "要使用一个变量 来间接操作 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置索引时的情况\n",
    "d = df_1.set_index(keys='年份')\n",
    "print(d.iloc[: , :4].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意在取消索引操作时，inplace=True 设置为 True，以便后面可以查看到取消后的情况\n",
    "d.reset_index(inplace=True)  \n",
    "d.iloc[: , :4].head()  # 取消索引时的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多级索引\n",
    "inplace=True 覆盖的情况下，直接使用 df_1 访问.\n",
    "\n",
    "<font color=\"red\">注意：</font>\n",
    "\n",
    "       在 inplace=True 覆盖原数据情况下，运行第 2 或多次，\n",
    "      就会出现报错的情况，同时代码并没有语法错误，\n",
    "      原因是原数据被覆盖了。解决方法是：重新运行所有代码，\n",
    "      如果不是很必要，尽量不要执行覆盖原数据的操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.set_index(keys=['地区', '年份'], inplace=True)  # 设置多级索引，覆盖原数据\n",
    "print(df_1.iloc[: , :4].head())  \n",
    "\n",
    "df_1.reset_index(inplace=True)\n",
    "df_1.iloc[: , :4].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、排序问题\n",
    "#### 通过索引排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_1.sample(n=5, replace=False)  # 通过随机不放回抽样 5 个数据\n",
    "# 通过索引排列，升序排列、不覆盖原数据、如有缺失值则放在前面\n",
    "data.sort_index(ascending=True, na_position='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多重索引的dataframe\n",
    "`dataframe.sort_index(level=[0,1],ascending=[False,True])`\n",
    "- level 按指定索引级别的值排"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 通过指定列的值排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.sort_values(by=['地区', '年份'], ascending=[True, False], inplace=False, na_position='first').head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6、重复数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 返回唯一值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n>>>', df_1['地区'].unique())  # 唯一值元素\n",
    "print('\\n>>>\\n', df_1.nunique())  # 唯一值数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重复值处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找重复值\n",
    "print('>>>\\n', df_1.duplicated(subset=['年份'], keep='first').head())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除重复值\n",
    "print('>>>\\n', df_1.drop_duplicates(subset=['年份'], keep='first', inplace=False).iloc[:, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查找重复索引\n",
    "print('\\n>>>', df_1.index.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7、数据分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 指定一列是聚合列，如：年份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '地区'作为索引分组，'年份'与分组列'地区'聚合\n",
    "# 第一种方法\n",
    "df_1.groupby(by=['地区'], as_index=True).agg({'年份': ['max', 'min', 'median']}).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二种方法，两种方法是等效的\n",
    "df_1.groupby(by=['地区'], as_index=True).年份.agg(['max', 'min', 'median']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 指定多列列是聚合列，如：年份、国内生产总值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.groupby(by=['地区'], as_index=True).agg({'年份': 'max', '国内生产总值': 'describe'}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 没有指定聚合列，则代表选择所有列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回所有列中的最大值\n",
    "df_1.groupby(by=['地区'], as_index=True).max().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8、处理缺失值\n",
    "在上面的探索中，发现有缺失值，因此有必要进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有数据的缺失情况\n",
    "df_1.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第一种方法，删除缺失值数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.dropna().isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 第二种方法，使用填充法填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n>>>\\n', df1.fillna(method='ffill').head())  # 使用缺失值的前一个值填充(前向填充)\n",
    "print('>>>\\n', df1.fillna(method='bfill').head())  # 使用缺失值的后一个值填充(后向填充)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' 平均值填充(所有列填充) '''\n",
    "print('>>>\\n', df_1.fillna(value=df_1.mean()).head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9、选择指定的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按标签选择\n",
    "\n",
    "    按行的序号、列的名称选择\n",
    "    df.loc[:, '列名']/df.loc[[0,1, 2], ['列名1', '列名2']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>>\\n', df_1.loc[:, '年份'].head())\n",
    "print('>>>\\n', df_1.loc[[0, 4, 7], ['年份', '国内生产总值']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按位置选择\n",
    "\n",
    "    按行位置(序号)、列位置选择\n",
    "    df.iloc[:, :]/da.iloc[[0, 1, 2], [2, 3, 4]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>>\\n', df_1.iloc[:3, :3])\n",
    "print('>>>\\n', df_1.iloc[[1, 34, 56], [2, 4, 8]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 按条件来选择 \n",
    "\n",
    "筛选出符合条件的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_1.set_index([\"地区\",\"年份\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 国内生产总值大于15678的数据\n",
    "df_1[df_1['国内生产总值'] > 15678].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择任一值大于1000的列\n",
    "df_1.loc[:, (df_1>10000).any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择所有值大于1000的列\n",
    "df_1.loc[:, (df_1>1000).all()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.loc[:, df_1.isnull().any()]  # 选择含 NaN值的列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_1.loc[:, df_1.notnull().all()]  # 选择不含NaN值的列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### query和filter\n",
    "在使用pandas进行数据分析时，经常遇到需要过滤信息的场景，此时我们可以用到2种函数，query和filter。\n",
    "\n",
    "#### query函数\n",
    "\n",
    "\n",
    "    query函数我认为类似sql语言中的where，可以对dataframe中的特定column进行筛选。具体语法如下：\n",
    "\n",
    "    df.query('列名   判断   值'),如df.query('column1 > 2 and column 2<1')\n",
    "\n",
    "    等于\n",
    "\n",
    "    df[df[列名] 判断 值],如 df[df[column1]>2 & df[column2]<1]\n",
    "\n",
    "\n",
    "#### filter函数\n",
    "\n",
    "    filter常规用法，在pandas说明里很好找到：\n",
    "\n",
    "    DataFrame.filter(items=None, like=None, regex=None, axis=None)\n",
    "\n",
    "    #items对列进行筛选#regex表示用正则进行匹配#like进行筛选#axis=0表示对行操作，axis=1表示对列操作\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择指定的列，类似于 df[['某列', '某列']]\n",
    "df_1.filter(items=['地区', '年份'])  # 选择指定的列\n",
    "df_1.filter(like='产业', axis=1)  # 选择含有 \"产业\" 的列"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
