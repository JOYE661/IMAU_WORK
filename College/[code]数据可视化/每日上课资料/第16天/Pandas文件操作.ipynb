{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas读取文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当使用 Pandas 做数据分析的时，需要读取事先准备好的数据集，这是做数据分析的第一步。Panda 提供了多种读取数据的方法：\n",
    "\n",
    "    read_csv() 用于读取文本文件\n",
    "    read_excel() 用于读取文本文件\n",
    "    read_json() 用于读取 json 文件\n",
    "    read_sql_query() 读取 sql 语句的，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通用流程\n",
    "\n",
    "    1. 导入库 import pandas as pd\n",
    "    2. 找到文件所在位置（绝对路径 = 全称）（相对路径 = 和程序在同一个文件夹中的路径的简称）\n",
    "    3. 变量名 = pd.读写操作方法（文件路径，具体的筛选条件，……）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV文件读取\n",
    "\n",
    "CSV 又称逗号分隔值文件，是一种简单的文件格式，以特定的结构来排列表格数据。 CSV 文件能够以纯文本形式存储表格数据，比如电子表格、数据库文件，并具有数据交换的通用格式。CSV 文件会在 Excel 文件中被打开，其行和列都定义了标准的数据格式。\n",
    "\n",
    "将 CSV 中的数据转换为 DataFrame 对象是非常便捷的。和一般文件读写不一样，它不需要你做打开文件、读取文件、关闭文件等操作。相反，您只需要一行代码就可以完成上述所有步骤，并将数据存储在 DataFrame 中。\n",
    "\n",
    "\n",
    "下面进行实例演示，源数据如下： \n",
    "<img src=\"images/20220424113515.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取文件:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 读取csv文件, 相对路径\n",
    "#df = pd.read_csv(\"data/my_csv.csv\")\n",
    "df = pd.read_csv(\"./data/my_csv.csv\")\n",
    "# os动态取得绝对路径 os.getcwd() os.path.json\n",
    "#df = pd.read_csv(r\"D:\\2021年财贸数据\\呼和浩特\\课件\\数据分析\\pandas\\第16天\\data\\my_csv.csv\")\n",
    "print(df,type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方法详细说明:\n",
    "    \n",
    "`read_csv(filepath_or_buffer, sep=',',  header='infer', names=None, index_col=None, usecols=None, squeeze=None, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=None, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, error_bad_lines=None, warn_bad_lines=None, on_bad_lines=None, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None, storage_options=None)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、基本参数\n",
    "\n",
    "    1、filepath_or_buffer：数据输入的路径：可以是文件路径、可以是URL，也可以是实现read方法的任意对象。这个参数，就是我们输入的第一个参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(r\"data\\students.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 还可以是一个URL，如果访问该URL会返回一个文件的话，那么pandas的read_csv函数会自动将\n",
    "# 该文件进行读取。比如：我们服务器上放的数据，将刚才的文件返回。\n",
    "pd.read_csv(\"http://my-teaching.top/static/data/students.csv\") #  需要网络请求,因此读取文件比较慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 里面还可以是一个 _io.TextIOWrapper，比如：\n",
    "f = open(r\"data\\students.csv\", encoding=\"utf-8\")\n",
    "pd.read_csv(f)\n",
    "# pandas默认使用utf-8读取文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    2、sep：读取csv文件时指定的分隔符，默认为逗号。注意：\"csv文件的分隔符\" 和 \"我们读取csv文件时指定的分隔符\" 一定要一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(r\"data\\students_step.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于指定的分隔符 和 csv文件采用的分隔符 不一致，因此多个列之间没有分开，而是连在一起了。 所以，我们需要将分隔符设置成\"\\t\"才可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data\\students_step.csv\", sep=\"|\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.delim_whitespace ：默认为 False，设置为 True 时，表示分割符为空白字符，可以是空格、\"\\t\"等等。不管分隔符是什么，只要是空白字符，那么可以通过delim_whitespace=True进行读取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data\\students_whitespace.txt\", sep=\" \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data\\students_whitespace.txt\", delim_whitespace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `header`:用作列名的行号，以及数据的开头。默认行为是推断列名：如果没有传递任何名称，则该行为与header=0相同，并且从文件的第一行推断列名，如果显式传递列名，则该行为与header=None相同。显式传递header=0以替换现有名称。标题可以是整数列表，指定列上多索引的行位置，例如[0,1,3]。未指定的中间行将被跳过（例如，本例中跳过2行）。请注意，如果skip_blank_lines=True，此参数将忽略注释行和空行，因此header=0表示数据的第一行，而不是文件的第一行。\n",
    "- `names`:当names没被赋值时，header会变成0，即选取数据文件的第一行作为列名；当 names 被赋值，header 没被赋值时，那么header会变成None。如果都赋值，就会实现两个参数的组合功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) names 没有被赋值，header 也没赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这种情况下，header为0，即选取文件的第一行作为表头\n",
    "pd.read_csv(r\"data\\students.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) names 没有被赋值，header 被赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不指定names，指定header为1，则选取第二行当做表头，第二行下面为数据\n",
    "pd.read_csv(r\"data\\students.csv\", header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) names 被赋值，header 没有被赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(r\"data\\students.csv\", names=[\"编号\", \"姓名\", \"地址\", \"性别\", \"出生日期\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，names适用于没有表头的情况，指定names没有指定header，那么header相当于None。\n",
    "一般来说，读取文件的时候会有一个表头，一般默认是第一行，但是有的文件中是没有表头的，那么这个时候就可以通过names手动指定、或者生成表头，而文件里面的数据则全部是内容。所以这里id、name、address、date也当成是一条记录了，本来它是表头的，但是我们指定了names，所以它就变成数据了，表头是我们在names里面指定的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) names和header都被赋值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(r\"data\\students.csv\", names=[\"编号\", \"姓名\", \"地址\", \"性别\", \"出生日期\"], header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个时候，相当于先不看names，只看header，header为0代表先把第一行当做表头，下面的当成数据；然后再把表头用names给替换掉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以names和header的使用场景主要如下：\n",
    "\n",
    "    ①. csv文件有表头并且是第一行，那么names和header都无需指定;\n",
    "    ②. csv文件有表头、但表头不是第一行，可能从下面几行开始才是真正的表头和数据，这个时候指定header即可;\n",
    "    ③. csv文件没有表头，全部是纯数据，那么我们可以通过names手动生成表头;\n",
    "    ④. csv文件有表头、但是这个表头你不想用，这个时候同时指定names和header。先用header选出表头和数据，然后再用names将表头替换掉，就等价于将数据读取进来之后再对列名进行rename；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4 index_col：我们在读取文件之后所得到的DataFrame的索引默认是0、1、2……，我们可以通过set_index设定索引，但是也可以在读取的时候就指定某列为索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"data\\students.csv\", index_col=\"birthday\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_datetime\n",
    "pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2004-11-02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['2002-02']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，我们在读取的时候指定了name列作为索引；\n",
    "此外，除了指定单个列，还可以指定多列作为索引，比如[\"id\", \"name\"]。同时，我们除了可以输入列名外，还可以输入列对应的索引。比如：\"id\"、\"name\"、\"address\"、\"date\"对应的索引就分别是0、1、2、3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(r\"data\\students.csv\", index_col=[\"gender\",\"birthday\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.loc[\"女\",\"2004/11/2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.sort_index(inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df2.loc[\"男\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5. usecols：返回列的子集。如果是类似列表的，则所有元素都必须是位置性的（即文档列中的整数索引），或者是与用户在名称中提供的列名或从文档标题行推断的列名相对应的字符串。如果给出了名称，则不考虑文档标题行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(r\"data\\students.csv\", usecols=[\"name\",\"birthday\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、通用解析参数\n",
    "\n",
    "    1. encoding:这只编码格式  utf-8  gbk\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(r\"data\\students_gbk.csv\") # UnicodeDecodeError "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 如果提示错误喂UnicodeDecodeError --->需要想到编码问题. 默认pandas使用utf-8格式读取.\n",
    "pd.read_csv(r\"data\\students_gbk.csv\", encoding=\"gbk\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. dtype：在读取数据的时候，设定字段的类型。比如，公司员工的id一般是：00001234，如果默认读取的时候，会显示为1234，所以这个时候要把他转为字符串类型，才能正常显示为00001234："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"data\\students_step_001.csv\", sep=\"|\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(r\"data\\students_step_001.csv\", sep=\"|\", dtype ={\"id\":str}) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3. converters：在读取数据的时候对列数据进行变换，例如将id增加10，但是注意 int(x)，在使用converters参数时，解析器默认所有列的类型为 str，所以需要进行类型转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', converters={\"id\": lambda x: int(x) + 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4.true_values和false_values：指定哪些值应该被清洗为True，哪些值被清洗为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', true_values=['男'], false_values=['女'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', true_values=['女'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的替换规则为，只有当某一列的数据类别全部出现在`true_values + false_values`里面，才会被替换。\n",
    "我们看到\"错\"并没有被替换成False，原因就是result字段中只有\"错\"这个类别的值在`true_values + false_values`中，而\"对\"并没有出现，所以不会替换。\n",
    "而最后的对、错都出现在了`true_values + false_values`中，所以全部被替换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    5、skiprows：表示过滤行，想过滤掉哪些行，就写在一个列表里面传递给skiprows即可。注意的是：这里是先过滤，然后再确定表头，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', skiprows=[0,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里把第一行过滤掉了，因为第一行是表头，所以在过滤掉之后第二行就变成表头了。\n",
    "当然里面除了传入具体的数值，来表明要过滤掉哪些行，还可以传入一个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', skiprows=lambda x: x > 0 and x % 2 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于索引从0开始，所以凡是索引大于0、并且%2等于0的记录都过滤掉。索引大于0，是为了保证表头不被过滤掉。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    6、skipfooter：从文件末尾过滤行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', skipfooter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', skipfooter=1, engine=\"python\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " pandas解析数据时用的引擎，目前解析引擎有两种：c、python。默认为 c，因为 c 引擎解析速度更快，但是特性没有 python 引擎全"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " skipfooter接收整型，表示从结尾往上过滤掉指定数量的行，因为引擎退化为python，那么要手动指定engine=\"python\"，不然会警告。另外需要指定encoding=\"utf-8\"，因为csv存在编码问题，当引擎退化为python的时候，在Windows上读取会乱码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    7、nrows：设置一次性读入的文件行数，在读入大文件时很有用，比如 16G 内存的PC无法容纳几百 G 的大文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、空值处理相关参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    na_values：该参数可以配置哪些值需要处理成 NaN："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data\\students.csv', na_values=[\"女\", \"朱梦雪\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到将\"女\"和\"朱梦雪\"设置成了NaN，这里的情况是不同的列中包含了不同的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四、时间处理相关参数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1、parse_dates：指定某些列为时间类型，这个参数一般搭配date_parser使用。\n",
    "\n",
    "    2、date_parser：是用来配合parse_dates参数的，因为有的列虽然是日期，但没办法直接转化，需要我们指定一个解析格式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data\\students.csv', parse_dates=[\"birthday\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data\\students_年月日.csv', parse_dates=[\"birthday\"])\n",
    "print(df2)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "df2 = pd.read_csv('data\\students_年月日.csv', \n",
    "                  parse_dates=[\"birthday\"],\n",
    "                  date_parser=lambda x: datetime.strptime(x, \"%Y年%m月%d日\"))\n",
    "print(df2)\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五、分块读入相关参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1、iterator：迭代器, iterator 为 bool类型，默认为False。如果为True，那么返回一个 TextFileReader 对象，以便逐块处理文件。这个在文件很大、内存无法容纳所有数据文件时，可以分批读入，依次处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = pd.read_csv('data\\students.csv', iterator=True)\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunk.get_chunk(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 文件还剩下三行，但是我们指定读取100，那么也不会报错，不够指定的行数，那么有多少返回多少\n",
    "print(chunk.get_chunk(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.get_chunk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # 但是在读取完毕之后，再读的话就会报错了\n",
    "    chunk.get_chunk(5)\n",
    "except StopIteration as e:\n",
    "    print(\"读取完毕\")\n",
    "# 读取完毕"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2、chunksize：整型，默认为 None，设置文件块的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = pd.read_csv('data\\students.csv', chunksize=2)\n",
    "# 还是返回一个类似于迭代器的对象\n",
    "print(chunk)  \n",
    "# <pandas.io.parsers.TextFileReader object at 0x0000025501143AF0>\n",
    "\n",
    "# 调用get_chunk，如果不指定行数，那么就是默认的chunksize\n",
    "print(chunk.get_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可以指定\n",
    "print(chunk.get_chunk(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    chunk.get_chunk(5)\n",
    "except StopIteration as e:\n",
    "    print(\"读取完毕\")\n",
    "# 读取完毕  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 以上便是pandas的read_csv函数中绝大部分参数了，同时其中的部分参数也适用于读取其它类型的文件。\n",
    "其实在读取csv文件时所使用的参数不多，很多参数平常我们都不会用到的，不过不妨碍我们了解一下，因为在某些特定的场景下它们是可以很方便地帮我们解决一些问题的。个人感觉分块读取这个参数最近在工作中提高了很大的效率。\n",
    "上面列到的read_csv函数中的参数并不是全部，有几个还没有介绍到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
